import requests
import csv
import os
import time
import random
import json
from fake_useragent import UserAgent

# D√©finir l'emplacement du fichier CSV et du dossier de sauvegarde
csv_file = "unique_urls.csv"  # Remplace par ton chemin vers le fichier CSV
output_folder = "saved_pages"  # Dossier principal
json_file = os.path.join(output_folder, "correspondances.json")  # Fichier JSON

# Dictionnaire pour stocker les correspondances URL ‚Üí fichier
if os.path.exists(json_file):
    with open(json_file, "r", encoding="utf-8") as f:
        correspondances = json.load(f)
    print(f"üìÑ JSON charg√© ({len(correspondances)} pages d√©j√† enregistr√©es)")
else:
    correspondances = {}

# G√©n√©rer un User-Agent al√©atoire
ua = UserAgent()

# Cr√©ation des sous-dossiers (article, edition, panorama, definitions)
categories = ["article", "edition", "panorama", "definitions"]
for category in categories:
    os.makedirs(os.path.join(output_folder, category), exist_ok=True)

# Ouvrir le fichier CSV et lire les URLs
with open(csv_file, mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)  # Supposons que le CSV a une colonne 'url'

    session = requests.Session()
    compteur = len(correspondances)  # Commencer √† partir des pages d√©j√† t√©l√©charg√©es

    for row in reader:
        url = row['url']

        # V√©rifier si l'URL a d√©j√† √©t√© t√©l√©charg√©e
        if url in correspondances:
            print(f"‚è≠Ô∏è D√©j√† t√©l√©charg√©e : {url}")
            continue  # Passer √† l'URL suivante

        print(f"üì• R√©cup√©ration de : {url}")

        # G√©n√©rer un User-Agent al√©atoire
        headers = {
            "User-Agent": ua.random,
        }

        for attempt in range(3):  # Essayer 3 fois en cas d‚Äô√©chec
            try:
                response = session.get(url, headers=headers, timeout=10)

                if response.status_code == 200:
                    # Extraire le type de contenu (article, edition, panorama, definitions)
                    parts = url.split("/")
                    if len(parts) > 4:
                        category = parts[3]  # Ex: "article", "edition", etc.
                    else:
                        category = "autres"  # Si non cat√©gorisable

                    # Cr√©er le bon dossier si ce n'est pas un des 4 connus
                    category_folder = os.path.join(output_folder, category)
                    os.makedirs(category_folder, exist_ok=True)

                    # Construire le nom du fichier
                    file_name = parts[-1] + ".html"
                    file_path = os.path.join(category_folder, file_name)

                    # Sauvegarder la page HTML
                    with open(file_path, "w", encoding="utf-8") as f:
                        f.write(response.text)

                    # Sauvegarder la correspondance URL ‚Üí fichier
                    correspondances[url] = file_path

                    # Mettre √† jour le JSON imm√©diatement apr√®s chaque sauvegarde
                    with open(json_file, "w", encoding="utf-8") as f:
                        json.dump(correspondances, f, indent=4, ensure_ascii=False)

                    compteur += 1  # Incr√©menter le compteur
                    print(f"‚úÖ Page sauvegard√©e sous {file_path} ({compteur})")
                    break  # Sortir de la boucle retry si succ√®s

                elif response.status_code == 403:
                    print(f"‚ö†Ô∏è Acc√®s interdit √† {url} (403). Possible blocage.")
                    break

                elif response.status_code == 429:
                    print(f"‚ö†Ô∏è Trop de requ√™tes (429). Attente de 30 secondes...")
                    time.sleep(30)  # Attente plus longue avant retry
                else:
                    print(f"‚ùå Erreur HTTP {response.status_code} pour {url}")

            except requests.exceptions.RequestException as e:
                print(f"‚ö†Ô∏è Erreur de connexion : {e}")

            # Attente al√©atoire entre 1 et 5 secondes pour √©viter d‚Äô√™tre bloqu√©
            time.sleep(random.uniform(1, 5))

print(f"\nüéØ {compteur} pages ont √©t√© t√©l√©charg√©es et class√©es.")
print(f"üìÇ Les correspondances sont sauvegard√©es dans {json_file}.")
